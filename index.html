<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<!-- saved from url=(0036)https://alphapav.github.io/SpareNet/ -->
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    
    <meta name="keywords" content="SpareNet">
    <meta name="description" content="SpareNet">
    <link href="./index_files/main.css" media="all" rel="stylesheet">
    <link rel="icon" type="image/png" href="https://alphapav.github.io/SpareNet/">
    <title>Style-based Point Generator with Adversarial Rendering for Point Cloud Completion</title>
    <link rel="preconnect" href="https://fonts.gstatic.com/">
    <link href="./index_files/css2" rel="stylesheet">
<script type="text/javascript" src="./index_files/jquery-1.12.4.min.js.download"></script></head>
<!-- <script type="text/x-mathjax-config">
    MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
  </script>
  <script type="text/javascript"
    src="http://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  </script> -->
  <!-- <script type="text/javascript" src="./files/MathJax.js"></script> -->

<body>
    <h3 align="center">CVPR 2021</h3>
   <h1 align="center">Style-based Point Generator with Adversarial Rendering for Point Cloud Completion</h1>
   
   <p align="center" style="font-size:18px">
    <a href="https://alphapav.github.io/"><span>Chulin Xie</span></a><sup>1</sup>*   
    <a href="https://chuxwa.github.io/"><span>Chuxin Wang</span></a><sup>2</sup>*  
    <a href="https://www.microsoft.com/en-us/research/people/zhanbo/"><span>Bo Zhang</span></a><sup>3</sup>  
    <a href="https://www.microsoft.com/en-us/research/people/haya/"><span>Hao Yang</span></a><sup>3</sup>  
    <a href="https://www.microsoft.com/en-us/research/people/doch/"><span>Dong Chen</span></a><sup>3</sup>  
    <a href="https://www.microsoft.com/en-us/research/people/fangwen/"><span>Fang Wen</span></a><sup>3</sup>  
   </p>
   <p align="center" style="font-size:18px">
        <sup>1</sup><a href="https://illinois.edu/">University of Illinois at Urbana-Champaign</a>    <sup>2</sup><a href="http://en.ustc.edu.cn/">University of Science and Technology of China</a>   
        <br><br> <sup>3</sup><a href="https://www.microsoft.com/en-us/research/lab/microsoft-research-asia/">Microsoft Research Asia</a>
    </p><p>
       
    </p><p align="center">
        *Equal contribution
    </p>    
    

    <p align="center"> <a href="https://arxiv.org/abs/2103.02535">[Paper]</a>   
        <a href="https://github.com/microsoft/SpareNet">[Code]</a>  
    </p>
    <h2>Abstract</h2>
     <hr>

    <p>
        In this paper, we proposed a novel Style-based Point Generator with Adversarial Rendering (SpareNet) for point cloud completion. 
        Firstly, we present the channel-attentive EdgeConv to fully exploit the local structures as well as the global shape in point features. 
        Secondly, we observe that the concatenation manner used by vanilla foldings limits its potential of generating a complex and faithful shape. Enlightened by the success of StyleGAN, we regard the shape feature as style code that modulates the normalization layers during the folding, which considerably enhances its capability. 
        Thirdly, we realize that existing point supervisions, e.g., Chamfer Distance or Earth Mover's Distance, cannot faithfully reflect the perceptual quality of the reconstructed points. To address this, we propose to project the completed points to depth maps with a differentiable renderer and apply adversarial training to advocate the perceptual realism under different viewpoints. Comprehensive experiments on ShapeNet and KITTI prove the effectiveness of our method, which achieves state-of-the-art quantitative performance while offering superior visual quality.  
    </p>
    <br>  

    <h2>Overview</h2>
    <hr>
    <p class="aligncenter">
        <img src="./index_files/overview.png" width="850" alt="centered image">
    </p>

   
    <p>
        The architecture of SpareNet. An encoder <b>E</b> encodes the partial points <b>X</b> into a shape code <b>g</b>, 
        leveraged by a style-based generator <b>G</b> to synthesize a coarse completion <b>Y<sub>c</sub></b>, 
        which is recurrently improved with refiner <b>R</b> into the final result <b>Y</b>. 
        Adversarial point rendering is applied to advocate the perceptual realism of completed points under different views.
    </p>
    <br>

    <h2>SpareNet</h2>
    <hr>
    <br><br><table id="tbInformation" width="100%">
        <tbody>
            <tr>
                <td rowspan="3">
                    <div class="smallimg"> 
                        <img src="./index_files/encoder.png" width="450" class="left">
                    </div>
                    
                </td>
          
                <td>
                   
                    <div class="smallpara">
                        <p> 
                            We devise the Channel Attentive EdgeConv (CAE) to simultaneously integrate both local and global context from point features. 
                            <!-- It is inspired by the EdgeConv that captures a local context and the Squeeze-and-Excitation blocks for capturing a global context.  -->
                             Our point encoder <b>E</b> heavily relies on the CAE blocks.  
                        </p>
                     </div>
                </td>
            </tr>
        </tbody>
        

        <tbody>
            <tr>
               
                <td>
                    <div class="smallpara">
                        <p> 
                            We present a style-based point generator <b>G</b> to generate a completed point cloud from the shape code <b>g</b> through novel style-based folding layers.
                        </p>
                     </div>
                </td>
                <td rowspan="3">
                    <div class="smallimg"> 
                        <img src="./index_files/generator.png" width="450" class="left">
                    </div>
                   
                </td>
            </tr>
        </tbody>
        
        <tbody>
            <tr>
    
                <td rowspan="1">
                    <div class="smallimg"> 
                        <img src="./index_files/render.png" width="450" class="left">
                    </div>
                   
                </td>
                <td>
                    <div class="smallpara">
                        <p> 
                            After generating a coarse point cloud <b>Y<sub>c</sub></b>, we additionally refine it to acquire a final result <b>Y</b> with improved quality. 
                            Our refinement guarantees an advantageous visual quality of our final point cloud <b>Y</b> by employing a novel adversarial point rendering.  
                        </p>
                     </div>
                    
                </td>
            </tr>
        </tbody>
    </table>

    <br>  
    <h2>Results</h2>
    <hr>
    <p class="aligncenter">
        <img src="./index_files/fig5.png" width="900" class="center">
    </p>

     
    <p align="center">
        Visualized completion comparison on ShapeNet.
    </p>
    <br>


    <h2>Paper</h2>
    <hr>

        
    <table id="tbInformation" width="100%">
        <tbody>
            <tr>
                <td rowspan="3">
                    <div class="shadow"> 
                        <img src="./index_files/firstpage.png" width="170">
                    </div>
                    
                </td>
                <td>
                    <div class="paper">                    
                        <p> 
                            <b>Style-based Point Generator with Adversarial Rendering for Point Cloud Completion </b>
                            <br>
                            Chulin Xie*, Chuxin Wang*, Bo Zhang, Hao Yang, Dong Chen, Fang Wen
                            <br>
                            Conference on Computer Vision and Pattern Recongnition (CVPR), 2021
                            <br>
                            <br>
                            <a href="https://arxiv.org/pdf/2103.02535.pdf">[PDF]</a> 
                            <a href="https://github.com/microsoft/SpareNet">[Code]</a> 
                            <a href="https://openaccess.thecvf.com/content/CVPR2021/html/Xie_Style-Based_Point_Generator_With_Adversarial_Rendering_for_Point_Cloud_Completion_CVPR_2021_paper.html">[CVPR 2021 Open Access]</a> 
                            <!-- <a href="">[Supplementary Materials]</a> -->
                            <a href="https://alphapav.github.io/SpareNet/files/cvpr21_poster_sparenet.pdf">[Poster]</a>
                            <a href="https://alphapav.github.io/SpareNet/files/cvpr21_bibtex.txt">[BibTeX]</a>
                        </p>
                </div>
                </td>
            </tr>
        </tbody>
    </table>

    <br>

    <p align="center">
        <font color="#999999">Last update: Mar, 2021</font>
    </p>

<div class="jvectormap-tip"></div>

</body></html>